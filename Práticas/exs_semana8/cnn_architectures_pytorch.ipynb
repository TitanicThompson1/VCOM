{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaU9_sOGzRD1"
      },
      "source": [
        "# CNN Architectures\n",
        "In this notebook we will explore standard CNN architectures using PyTorch and torchvision.\n",
        "\n",
        "You can find more information on how to finetune pretrained models [here](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvfTDUXuzRD9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "# !pip install torchsummary\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDBhCwhszREA"
      },
      "source": [
        "### CIFAR10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5IQVCmOzREB"
      },
      "outputs": [],
      "source": [
        "# since we are going to use pretrained CNNs (on ImageNet), we need to normalize our data \n",
        "# according to the mean and std with which these networks were trained, i.e. with the statistics of the ImageNet dataset\n",
        "data_aug = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  ])\n",
        "\n",
        "training_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=data_aug,\n",
        ")\n",
        "validation_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=data_aug,\n",
        ")\n",
        "print(f\"Training size: {len(training_data)} \\nValidation size: {len(validation_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByDvrH3z1uOT"
      },
      "outputs": [],
      "source": [
        "# get cpu or gpu device for training\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# now we need to define a Dataloader, which allows us to automatically batch our inputs, do sampling and multiprocess data loading\n",
        "batch_size = 64\n",
        "num_workers = 2 # how many processes are used to load the data\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
        "validation_dataloader = DataLoader(validation_data, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1kRGiw_zREE"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxSdayviCWk5"
      },
      "outputs": [],
      "source": [
        "def epoch_iter(dataloader, model, loss_fn, optimizer=None, is_train=True):\n",
        "    if is_train:\n",
        "      assert optimizer is not None, \"When training, please provide an optimizer.\"\n",
        "      \n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    if is_train:\n",
        "      model.train() # put model in train mode\n",
        "    else:\n",
        "      model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    preds = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.set_grad_enabled(is_train):\n",
        "      for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
        "          X, y = X.to(device), y.to(device)\n",
        "\n",
        "          # Compute prediction error\n",
        "          pred = model(X)\n",
        "          loss = loss_fn(pred, y)\n",
        "\n",
        "          if is_train:\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "          # Save training metrics\n",
        "          total_loss += loss.item() # IMPORTANT: call .item() to obtain the value of the loss WITHOUT the computational graph attached\n",
        "\n",
        "          probs = F.softmax(pred, dim=1)\n",
        "          final_pred = torch.argmax(probs, dim=1)\n",
        "          preds.extend(final_pred.cpu().numpy())\n",
        "          labels.extend(y.cpu().numpy())\n",
        "\n",
        "    return total_loss / num_batches, accuracy_score(labels, preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmsUVGS6C0O1"
      },
      "outputs": [],
      "source": [
        "def train(model, model_name, num_epochs, train_dataloader, validation_dataloader, loss_fn, optimizer):\n",
        "  train_history = {'loss': [], 'accuracy': []}\n",
        "  val_history = {'loss': [], 'accuracy': []}\n",
        "  best_val_loss = np.inf\n",
        "  print(\"Start training...\")\n",
        "  for t in range(num_epochs):\n",
        "      print(f\"\\nEpoch {t+1}\")\n",
        "      train_loss, train_acc = epoch_iter(train_dataloader, model, loss_fn, optimizer)\n",
        "      print(f\"Train loss: {train_loss:.3f} \\t Train acc: {train_acc:.3f}\")\n",
        "      val_loss, val_acc = epoch_iter(validation_dataloader, model, loss_fn, is_train=False)\n",
        "      print(f\"Val loss: {val_loss:.3f} \\t Val acc: {val_acc:.3f}\")\n",
        "\n",
        "      # save model when val loss improves\n",
        "      if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        save_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': t}\n",
        "        torch.save(save_dict, model_name + '_best_model.pth')\n",
        "\n",
        "      # save latest model\n",
        "      save_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': t}\n",
        "      torch.save(save_dict, model_name + '_latest_model.pth')\n",
        "\n",
        "      # save training history for plotting purposes\n",
        "      train_history[\"loss\"].append(train_loss)\n",
        "      train_history[\"accuracy\"].append(train_acc)\n",
        "\n",
        "      val_history[\"loss\"].append(val_loss)\n",
        "      val_history[\"accuracy\"].append(val_acc)\n",
        "      \n",
        "  print(\"Finished\")\n",
        "  return train_history, val_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xr48TEVlzREH"
      },
      "outputs": [],
      "source": [
        "def plotTrainingHistory(train_history, val_history):\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.title('Cross Entropy Loss')\n",
        "    plt.plot(train_history['loss'], label='train')\n",
        "    plt.plot(val_history['loss'], label='val')\n",
        "    plt.legend(loc='best')\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.title('Classification Accuracy')\n",
        "    plt.plot(train_history['accuracy'], label='train')\n",
        "    plt.plot(val_history['accuracy'], label='val')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7x7 versus 3x3 Convolutions\n",
        "\n",
        "Historically, the VGG was the first CNN architecture to introduce more layers (16-19 layers versus the 8 layers of AlexNet) and smaller convolutional kernel sizes (3x3).\n",
        "\n",
        "This is mainly due to the fact that a stack of 3 3x3 convolutional layers (with stride 1) has the same effective receptive field as a single 7x7 layer. Why?\n",
        "\n",
        "You can find out more about the effective receptive field of CNNs and explore some visualizations [here](https://blog.mlreview.com/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807).\n",
        "\n",
        "Compare the number of parameters of a single convolutional layer with 7x7 kernel with a stack of 3 convolutional layers with 3x3 kernels."
      ],
      "metadata": {
        "id": "cZSe3Knytp5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "# consider convolutional layers with 1 input and output channels\n",
        "# hint: use the summary method from the torchsummary package"
      ],
      "metadata": {
        "id": "6hg9leFzuRf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are the advantages of using a stack of 3 convolutional layers with 3x3 kernels instead of a single 7x7 layer?"
      ],
      "metadata": {
        "id": "7Lc1auKjyMfr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aqWR_0VzRED"
      },
      "source": [
        "### VGG model\n",
        "\n",
        "Finetune a VGG-16 model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfK3c9RSzRED"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# load model from torchvision (with pretrained=True)\n",
        "vgg =\n",
        "\n",
        "# change the number of neurons in the last layer to the number of classes of the problem at hand (CIFAR10 dataset)\n",
        "\n",
        "vgg.to(device)\n",
        "print(vgg)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect the model structure.\n",
        "\n",
        "What does the AdaptiveAvgPool2d layer do?\n",
        "\n",
        "What is the shape of the feature map before and after this layer?"
      ],
      "metadata": {
        "id": "JX-vNZF3fiqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "model_name = 'vgg16'\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss() # already includes the Softmax activation\n",
        "optimizer_vgg = torch.optim.SGD(vgg.parameters(), lr=1e-3)\n",
        "\n",
        "vgg_train_history, vgg_val_history = train(vgg, model_name, num_epochs, train_dataloader, validation_dataloader, loss_fn, optimizer_vgg)\n",
        "\n",
        "plotTrainingHistory(vgg_train_history, vgg_val_history)"
      ],
      "metadata": {
        "id": "aAl5WoxWlwcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet Model\n",
        "Repeat the finetuning process with a ResNet-50 model."
      ],
      "metadata": {
        "id": "aDzxzS63q4AP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "# load model from torchvision (with pretrained=True)\n",
        "resnet = \n",
        "\n",
        "# change the number of neurons in the last layer to the number of classes of the problem at hand (CIFAR10 dataset)\n",
        "\n",
        "resnet.to(device)\n",
        "print(resnet)"
      ],
      "metadata": {
        "id": "MTZd8yFhrL9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "model_name = 'resnet50'\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss() # already includes the Softmax activation\n",
        "optimizer_resnet = torch.optim.SGD(resnet.parameters(), lr=1e-3)\n",
        "\n",
        "resnet_train_history, resnet_val_history = train(resnet, model_name, num_epochs, train_dataloader, validation_dataloader, loss_fn, optimizer_resnet)\n",
        "\n",
        "plotTrainingHistory(resnet_train_history, resnet_val_history)"
      ],
      "metadata": {
        "id": "oMlKInxPrgS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare the VGG and ResNet models in terms of:\n",
        "\n",
        "\n",
        "1.   number of parameters\n",
        "2.   validation accuracy\n",
        "3.   training time\n",
        "\n",
        "What is the main difference introduced by the ResNet architecture?\n"
      ],
      "metadata": {
        "id": "u6pf9u38zADi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "# use torchsummary to compare the number of parameters of the VGG-16 and the ResNet-50"
      ],
      "metadata": {
        "id": "fEtXUkArZx8J"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "cnn_architectures_pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}